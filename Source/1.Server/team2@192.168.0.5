"TurtleBot ì „ìš© ìŠ¤íŠ¸ë¦¬ë° í´ë¼ì´ì–¸íŠ¸ (ROS2 ì˜¤ë„ë©”íŠ¸ë¦¬ ë° ë¼ì¸ ì„¼ì„œ í†µí•©)."

import math
import socket
import struct
import sys
import threading
import time
from typing import Optional, Tuple

import cv2

try:
    import rclpy
    from geometry_msgs.msg import Twist
    from nav_msgs.msg import Odometry
    from rclpy.node import Node
    from rclpy.time import Time
except ImportError:  # noqa: F401
    rclpy = None  # type: ignore
    Odometry = None  # type: ignore
    Node = None  # type: ignore
    Twist = None  # type: ignore
    Time = None # type: ignore

try:
    import RPi.GPIO as GPIO
except (ImportError, RuntimeError):
    GPIO = None


AUTH_PROMPT = "AUTH_REQUEST"
AUTH_OK = "AUTH_OK"
CLIENT_ID = "TURTLE01"
CLIENT_PASSWORD = "TURTLE1234"

#SERVER_ADDR: Tuple[str, int] = ("10.10.16.29", 9999)
SERVER_ADDR: Tuple[str, int] = ("127.0.0.1", 9999)
FRAME_SIZE = (1280,720)  # (width, height)
TARGET_FPS = 40        # 0 => no sleep, otherwise throttle
JPEG_QUALITY = 85
ODOM_TOPIC = "/odom"
POSE_SEND_INTERVAL = 0.2  # seconds
CAMERA_FAILURE_LIMIT = 5
CAMERA_FORMAT_CANDIDATES = ["MJPG", "YUYV", "YUY2", "UYVY", "NV12", "YU12"]
YAW_TOLERANCE = 0.02
ANGULAR_KP = 1.5
MAX_ANGULAR_SPEED = 0.9


def quaternion_to_yaw(w: float, x: float, y: float, z: float) -> float:
    """geometry_msgs/Quaternion â†’ yaw(ë¼ë””ì•ˆ) ë³€í™˜."""
    siny_cosp = 2.0 * (w * z + x * y)
    cosy_cosp = 1.0 - 2.0 * (y * y + z * z)
    return math.atan2(siny_cosp, cosy_cosp)


def decode_fourcc(value: float) -> str:
    """OpenCV ë°˜í™˜ ê°’ì„ FOURCC ë¬¸ìì—´ë¡œ ë³€í™˜."""
    code = int(value)
    chars = [chr((code >> (8 * i)) & 0xFF) for i in range(4)]
    result = "".join(chars)
    return result if result.strip("\x00") else "----"


def try_set_fourcc(cap: cv2.VideoCapture, fourcc: str) -> bool:
    """ì§€ì •í•œ FOURCCë¥¼ ì„¤ì •í•˜ê³  ì‹¤ì œ ì ìš© ì—¬ë¶€ë¥¼ í™•ì¸."""
    code = cv2.VideoWriter_fourcc(*fourcc)
    if not cap.set(cv2.CAP_PROP_FOURCC, code):
        return False
    applied = decode_fourcc(cap.get(cv2.CAP_PROP_FOURCC))
    return applied == fourcc

def normalize_angle(angle: float) -> float:
    return (angle + math.pi) % (2 * math.pi) - math.pi


class OdometryBridge:
    """ROS2 ì˜¤ë„ë©”íŠ¸ë¦¬ êµ¬ë…, ë¼ì¸ ì„¼ì„œ ì½ê¸°, cmd_vel ë°œí–‰ì„ í†µí•©í•œ ë¸Œë¦¬ì§€."""

    def __init__(self, odom_topic: str = ODOM_TOPIC, cmd_vel_topic: str = "/cmd_vel") -> None:
        self.odom_topic = odom_topic
        self.cmd_vel_topic = cmd_vel_topic
        self._lock = threading.Lock()
        self._latest_pose: Tuple[float, float, float] = (0.0, 0.0, 0.0)
        self._latest_sensor: Tuple[int, int] = (0, 0)
        self._has_pose = False
        self._origin: Optional[Tuple[float, float]] = None
        self._thread: Optional[threading.Thread] = None
        self._running = False
        self._node: Optional["OdometryBridge._BridgeNode"] = None
        self._owns_context = False

    class _BridgeNode(Node):
        def __init__(self, parent: "OdometryBridge", odom_topic: str, cmd_vel_topic: str) -> None:
            super().__init__("turtle_client_bridge")
            self._parent = parent
            self._cmd_pub = self.create_publisher(Twist, cmd_vel_topic, 10)
            self.create_subscription(Odometry, odom_topic, self._odom_callback, 10)
            self._gpio_initialized = False

            if GPIO:
                try:
                    GPIO.setmode(GPIO.BCM)
                    self._left_pin = 17
                    self._right_pin = 27
                    GPIO.setup(self._left_pin, GPIO.IN)
                    GPIO.setup(self._right_pin, GPIO.IN)
                    self.create_timer(0.05, self._read_line_sensor) # 20Hz
                    self.get_logger().info("ğŸ“¡ Line Sensor GPIO integration enabled.")
                    self._gpio_initialized = True
                except Exception as e:
                    self.get_logger().error(f"Failed to initialize GPIO for line sensor: {e}")
            else:
                self.get_logger().warn("RPi.GPIO not found, line sensor is disabled.")

        def _odom_callback(self, msg: Odometry) -> None:
            pose = msg.pose.pose
            self._parent._set_pose(
                float(pose.position.x),
                float(pose.position.y),
                quaternion_to_yaw(pose.orientation.w, pose.orientation.x, pose.orientation.y, pose.orientation.z),
            )

        def _read_line_sensor(self) -> None:
            if not self._gpio_initialized:
                return
            try:
                L = GPIO.input(self._left_pin)
                R = GPIO.input(self._right_pin)
                self._parent._set_line_sensor((L, R))
            except Exception as e:
                self.get_logger().error(f"Error reading line sensor data: {e}")

        def publish_velocity(self, linear_x: float, angular_z: float) -> None:
            twist = Twist()
            twist.linear.x = linear_x
            twist.angular.z = angular_z
            self._cmd_pub.publish(twist)

        def cleanup_gpio(self) -> None:
            if self._gpio_initialized:
                GPIO.cleanup()
                self.get_logger().info("GPIO cleaned up.")
        
        def get_ros_time(self) -> float:
            return self.get_clock().now().nanoseconds / 1e9

    def start(self) -> bool:
        if rclpy is None or Node is None or Odometry is None or Twist is None:
            print("rclpy íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ROS2 ê¸°ëŠ¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        if self._running:
            return True
        try:
            if not rclpy.ok():
                rclpy.init(args=None)
                self._owns_context = True
            else:
                self._owns_context = False
            self._node = self._BridgeNode(self, self.odom_topic, self.cmd_vel_topic)
            self._running = True
            self._thread = threading.Thread(target=self._spin, daemon=True)
            self._thread.start()
            print(f"ROS2 ë¸Œë¦¬ì§€ ì‹œì‘: ì˜¤ë„ë©”íŠ¸ë¦¬({self.odom_topic}), ë¼ì¸ì„¼ì„œ(GPIO)")
            return True
        except Exception as exc:  # noqa: BLE001
            print(f"ROS2 ë¸Œë¦¬ì§€ ì´ˆê¸°í™” ì‹¤íŒ¨: {exc}")
            self.stop()
            return False

    def _spin(self) -> None:
        try:
            while self._running and rclpy.ok():
                rclpy.spin_once(self._node, timeout_sec=0.1)
        finally:
            if self._node is not None:
                try:
                    if hasattr(self._node, "cleanup_gpio"):
                        self._node.cleanup_gpio()
                    self._node.destroy_node()
                except Exception:  # noqa: BLE001
                    pass
                self._node = None
            if self._owns_context and rclpy is not None and rclpy.ok():
                try:
                    rclpy.shutdown()
                except Exception:  # noqa: BLE001
                    pass
            self._owns_context = False
            self._running = False

    def stop(self) -> None:
        if not self._running:
            return
        self._running = False
        if self._thread is not None and self._thread.is_alive():
            self._thread.join(timeout=1.0)
        self._thread = None

    def _set_pose(self, x: float, y: float, yaw: float) -> None:
        with self._lock:
            if self._origin is None:
                self._origin = (x, y)
            self._latest_pose = (x, y, yaw)
            self._has_pose = True
    
    def _set_line_sensor(self, sensor_data: Tuple[int, int]) -> None:
        with self._lock:
            self._latest_sensor = sensor_data

    def get_pose(self, *, relative: bool = False) -> Tuple[float, float, float]:
        with self._lock:
            x, y, yaw = self._latest_pose
            if relative and self._origin is not None:
                ox, oy = self._origin
                return (x - ox, y - oy, yaw)
            return (x, y, yaw)

    def get_line_sensor(self) -> Tuple[int, int]:
        with self._lock:
            return self._latest_sensor

    def has_pose(self) -> bool:
        with self._lock:
            return self._has_pose

    def send_velocity(self, linear_x: float, angular_z: float) -> None:
        if self._node is None:
            return
        self._node.publish_velocity(linear_x, angular_z)

    def get_time(self) -> float:
        if self._node:
            return self._node.get_ros_time()
        return time.time()


class MotionController:
    """ì§ì„ /íšŒì „/ë¼ì¸ì¶”ì  ì œì–´ë¥¼ ìˆ˜í–‰í•˜ëŠ” í†µí•© ì»¨íŠ¸ë¡¤ëŸ¬."""

    def __init__(self, bridge: OdometryBridge, notify_cb) -> None:
        self._bridge = bridge
        self._notify_cb = notify_cb
        self._lock = threading.Lock()
        self._running = True
        
        # Motion states
        self._target: Optional[Tuple[float, float]] = None
        self._manual_active = False
        self._manual_linear = 0.0
        self._manual_angular = 0.0
        self._line_tracing_active = False
        self._cancel_requested = False

        # Line tracer states
        self._lt_left_sweep_angle = math.radians(180)
        self._lt_right_sweep_angle = math.radians(180)
        self._lt_scan_angular_speed = 0.6
        self._lt_linear_speed = 0.1
        self._lt_angular_speed = 0.1
        self._lt_calibration_active = False
        self._lt_calibration_direction = 1.0
        self._lt_calibration_remaining = 0.0
        self._lt_last_calibration_time = 0.0
        self._lt_tracking_started = False

        self._thread = threading.Thread(target=self._loop, daemon=True)
        self._thread.start()

    def move_to(self, target: Tuple[float, float]) -> None:
        if not self._bridge.start():
            print("ROS2 ë¸Œë¦¬ì§€ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ì–´ ì´ë™ ëª…ë ¹ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        with self._lock:
            self._target = target
            self._manual_active = False
            self._line_tracing_active = False
            self._cancel_requested = False
        print(f"[ëª¨ì…˜] ëª©í‘œ ì¢Œí‘œ rel({target[0]:.2f}, {target[1]:.2f}) ì´ë™ ì‹œì‘")

    def set_manual_velocity(self, linear: float, angular: float) -> None:
        if not self._bridge.start():
            print("ROS2 ë¸Œë¦¬ì§€ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ì–´ ìˆ˜ë™ ì œì–´ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        with self._lock:
            self._target = None
            self._line_tracing_active = False
            self._manual_linear = linear
            self._manual_angular = angular
            self._manual_active = abs(linear) > 1e-4 or abs(angular) > 1e-4
            self._cancel_requested = False
        if not self._manual_active:
            self._bridge.send_velocity(0.0, 0.0)

    def start_line_tracing(self) -> None:
        if not self._bridge.start():
            print("ROS2 ë¸Œë¦¬ì§€ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ì–´ ë¼ì¸ ì¶”ì ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        print("[ëª¨ì…˜] ë¼ì¸ ì¶”ì  ì‹œì‘")
        with self._lock:
            self._target = None
            self._manual_active = False
            self._cancel_requested = False
            self._line_tracing_active = True
            # Initialize calibration state
            self._lt_calibration_active = True
            self._lt_tracking_started = False
            self._lt_calibration_direction = 1.0
            self._lt_calibration_remaining = self._lt_left_sweep_angle
            self._lt_last_calibration_time = self._bridge.get_time()
        print("[ëª¨ì…˜] ë¼ì¸ ì¶”ì  ì¤€ë¹„: ì„¼ì„œ [1,1]ì„ ì°¾ê¸° ìœ„í•´ ì¢Œ/ìš° íšŒì „ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    def cancel(self) -> None:
        with self._lock:
            if self._target is None and not self._manual_active and not self._line_tracing_active:
                return
            self._target = None
            self._manual_active = False
            self._line_tracing_active = False
            self._cancel_requested = True
        self._bridge.send_velocity(0.0, 0.0)
        self._notify_cb("stop@done")
        print("[ëª¨ì…˜] ëª¨ë“  ì´ë™ ì·¨ì†Œ ë° ì •ì§€")

    def stop(self) -> None:
        self._running = False
        self.cancel()
        self._thread.join(timeout=1.0)

    def _loop(self) -> None:
        while self._running:
            with self._lock:
                # Copy states to local variables
                is_line_tracing = self._line_tracing_active
                is_manual = self._manual_active
                target_point = self._target
                manual_linear = self._manual_linear
                manual_angular = self._manual_angular
                is_cancelled = self._cancel_requested

            if is_cancelled or (not is_line_tracing and not is_manual and target_point is None):
                time.sleep(0.05)
                continue

            if not self._bridge.has_pose():
                self._bridge.send_velocity(0.0, 0.0)
                time.sleep(0.05)
                continue
            
            if is_line_tracing:
                self._line_tracer_step()
            elif is_manual:
                self._bridge.send_velocity(manual_linear, manual_angular)
            elif target_point is not None:
                self._move_to_step(target_point)
            
            time.sleep(0.05)

    def _move_to_step(self, target: Tuple[float, float]) -> None:
        kp = 0.8
        max_speed = 0.35
        min_speed = 0.05
        goal_tolerance = 0.03
        
        rel_x, rel_y, yaw = self._bridge.get_pose(relative=True)
        dx = target[0] - rel_x
        dy = target[1] - rel_y
        distance = math.hypot(dx, dy)

        if distance <= goal_tolerance:
            self._bridge.send_velocity(0.0, 0.0)
            with self._lock:
                self._target = None
                self._cancel_requested = False
            self._notify_cb("move@done")
            return

        target_yaw = math.atan2(dy, dx)
        yaw_error = normalize_angle(target_yaw - yaw)

        linear_speed = 0.0
        angular_speed = 0.0

        if abs(yaw_error) > YAW_TOLERANCE:
            angular_speed = ANGULAR_KP * yaw_error
            angular_speed = max(min(angular_speed, MAX_ANGULAR_SPEED), -MAX_ANGULAR_SPEED)
        else:
            linear_speed = kp * distance
            linear_speed = max(min(linear_speed, max_speed), min_speed)

        self._bridge.send_velocity(linear_speed, angular_speed)

    def _line_tracer_step(self) -> None:
        # This function combines the logic from LineTracerRemote
        raw_left, raw_right = self._bridge.get_line_sensor()

        with self._lock:
            if not self._line_tracing_active:
                return # State changed by another thread

            if self._lt_calibration_active:
                # Check for calibration success
                if raw_left == 1 and raw_right == 1:
                    print("[ëª¨ì…˜] ì„¼ì„œ [1,1] ê°ì§€ â†’ ë¼ì¸ ì¶”ì  ì¤€ë¹„ ì™„ë£Œ.")
                    self._lt_calibration_active = False
                    self._lt_tracking_started = False
                    self._bridge.send_velocity(0.0, 0.0)
                    print("[ëª¨ì…˜] ë¼ì¸ ì¶”ì  ì¤€ë¹„ ë‹¨ê³„ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë¼ì¸ íŠ¸ë ˆì´ì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    return

                # Perform calibration rotation
                now = self._bridge.get_time()
                delta = now - self._lt_last_calibration_time
                self._lt_last_calibration_time = now
                self._lt_calibration_remaining -= abs(self._lt_scan_angular_speed) * delta
                
                angular_z = self._lt_calibration_direction * self._lt_scan_angular_speed
                self._bridge.send_velocity(0.0, angular_z)

                if self._lt_calibration_remaining <= 0.0:
                    if self._lt_calibration_direction > 0:
                        self._lt_calibration_direction = -1.0
                        self._lt_calibration_remaining = self._lt_right_sweep_angle
                        print("[ëª¨ì…˜] ë¼ì¸ ì¶”ì  ì¤€ë¹„: ì˜¤ë¥¸ìª½ìœ¼ë¡œ íšŒì „")
                    else:
                        self._lt_calibration_direction = 1.0
                        self._lt_calibration_remaining = self._lt_left_sweep_angle
                        print("[ëª¨ì…˜] ë¼ì¸ ì¶”ì  ì¤€ë¹„: ì™¼ìª½ìœ¼ë¡œ íšŒì „")
                return

            # --- Line Tracking Logic ---
            left_on_line = raw_left == 1
            right_on_line = raw_right == 1
            linear_x, angular_z = 0.0, 0.0

            if left_on_line and right_on_line:
                linear_x = self._lt_linear_speed
                angular_z = 0.0
                if not self._lt_tracking_started:
                    print("[ëª¨ì…˜] ë¼ì¸ ì¶”ì  ì‹œì‘ë¨.")
                    self._lt_tracking_started = True
            elif left_on_line and not right_on_line:
                angular_z = self._lt_angular_speed
            elif right_on_line and not left_on_line:
                angular_z = -self._lt_angular_speed
            else: # Both sensors off the line
                if self._lt_tracking_started:
                    # Lost the line, stop and notify server
                    self._bridge.send_velocity(0.0, 0.0)
                    print("[ëª¨ì…˜] ì„¼ì„œ [0,0] ê°ì§€ â†’ ë¼ì¸ ì¶”ì  ì™„ë£Œ.")
                    self._line_tracing_active = False
                    self._lt_tracking_started = False
                    self._notify_cb("trace@done")
                    return
                else:
                    # Still in initial search, do nothing until calibration finds the line
                    angular_z = self._lt_scan_angular_speed * self._lt_calibration_direction

            self._bridge.send_velocity(linear_x, angular_z)


def configure_capture() -> Tuple[cv2.VideoCapture, float]:
    """ì¹´ë©”ë¼ë¥¼ ë¹ ë¥´ê²Œ ì´ˆê¸°í™”í•˜ê³  ì„¼ì„œ FPSë¥¼ ë°˜í™˜."""
    cap = cv2.VideoCapture(0, cv2.CAP_V4L2)
    if not cap.isOpened():
        raise RuntimeError("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    chosen_fourcc = None
    for candidate in CAMERA_FORMAT_CANDIDATES:
        if try_set_fourcc(cap, candidate):
            chosen_fourcc = candidate
            break
    if chosen_fourcc is None:
        print("ì§€ì›ë˜ëŠ” FOURCC í¬ë§·ì„ ì ìš©í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
    else:
        print(f"ì¹´ë©”ë¼ FOURCC ì ìš©: {chosen_fourcc}")

    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_SIZE[0])
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_SIZE[1])
    applied_fourcc = decode_fourcc(cap.get(cv2.CAP_PROP_FOURCC))

    requested_fps = float(TARGET_FPS) if TARGET_FPS > 0 else 0.0
    if requested_fps > 0:
        cap.set(cv2.CAP_PROP_FPS, requested_fps)
    else:
        cap.set(cv2.CAP_PROP_FPS, 30.0)

    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    actual_w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
    actual_h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
    sensor_fps = cap.get(cv2.CAP_PROP_FPS)

    if requested_fps > 0 and sensor_fps > requested_fps + 1e-3:
        print(
            f"ì¹´ë©”ë¼ ì„¤ì •: {actual_w:.0f}x{actual_h:.0f} @ {sensor_fps:.1f}fps"
            f" (FOURCC {applied_fourcc})"
            f" (ìš”ì²­ {requested_fps:.1f}fps, ì „ì†¡ì€ {requested_fps:.1f}fpsë¡œ ì œí•œ)"
        )
    else:
        print(f"ì¹´ë©”ë¼ ì„¤ì •: {actual_w:.0f}x{actual_h:.0f} @ {sensor_fps:.1f}fps (FOURCC {applied_fourcc})")

    return cap, sensor_fps


def _recv_line(sock: socket.socket) -> Optional[str]:
    data = bytearray()
    while b"\n" not in data:
        chunk = sock.recv(1024)
        if not chunk:
            return None
        data.extend(chunk)
    try:
        return data.split(b"\n", 1)[0].decode("utf-8").strip()
    except UnicodeDecodeError:
        return None


def authenticate(sock: socket.socket) -> bool:
    prompt = _recv_line(sock)
    if prompt != AUTH_PROMPT:
        print("ì„œë²„ ì¸ì¦ í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return False

    credential = f"{CLIENT_ID}:{CLIENT_PASSWORD}\n".encode("utf-8")
    sock.sendall(credential)

    response = _recv_line(sock)
    if response == AUTH_OK:
        print("ì„œë²„ ì¸ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤.")
        return True

    print("ì„œë²„ ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ID/Passwordë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    return False

def handle_server_message(line: str, motion: Optional[MotionController]) -> None:
    if not line or motion is None:
        return
    
    upper = line.strip().upper()
    
    if upper == "TRACE_LINE":
        print(f"TRACE_LINE ëª…ë ¹ ìˆ˜ì‹ ")
        motion.start_line_tracing()
    elif line.startswith("MOVE:"):
        print(f"MOVE ëª…ë ¹ ìˆ˜ì‹ : {line}")
        try:
            _, payload = line.split(":", 1)
            start_raw, target_raw = payload.split("->", 1)
            tx_str, ty_str = target_raw.split(",", 1)
            tx = float(tx_str)
            ty = float(ty_str)
            motion.move_to((tx, ty))
        except ValueError:
            print(f"MOVE ëª…ë ¹ íŒŒì‹± ì‹¤íŒ¨: {line}")
    elif upper == "STOP":
        print("STOP ëª…ë ¹ ìˆ˜ì‹ : ì¦‰ì‹œ ì •ì§€í•©ë‹ˆë‹¤.")
        motion.cancel()
    elif line.startswith("TURN:"):
        try:
            _, payload = line.split(":", 1)
            parts = [p.strip() for p in payload.split(",") if p.strip()]
            if not parts:
                return
            if len(parts) == 1:
                linear = 0.0
                angular = float(parts[0])
            else:
                linear = float(parts[0])
                angular = float(parts[1])
        except ValueError:
            print(f"TURN ëª…ë ¹ íŒŒì‹± ì‹¤íŒ¨: {line}")
            return
        motion.set_manual_velocity(linear, angular)
    else:
        print(f"ì„œë²„ ë©”ì‹œì§€: {line}")

def receive_async(sock: socket.socket, motion: Optional[MotionController]) -> None:
    buffer = bytearray()
    while True:
        try:
            chunk = sock.recv(1024)
            if not chunk:
                print("ì„œë²„ì™€ì˜ ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤.")
                break
            buffer.extend(chunk)
            while b"\n" in buffer:
                raw, _, remainder = buffer.partition(b"\n")
                buffer = bytearray(remainder)
                line = raw.decode("utf-8", errors="ignore").strip()
                if line:
                    handle_server_message(line, motion)
        except OSError:
            print("ë©”ì‹œì§€ ìˆ˜ì‹  ìŠ¤ë ˆë“œ ì˜¤ë¥˜.")
            break

def send_control_message(sock: socket.socket, message: str) -> None:
    text = message.strip()
    if not text:
        return
    payload = (text + "\n").encode("utf-8")
    header = struct.pack(">L", 0)
    try:
        sock.sendall(header + payload)
        print(f"ì„œë²„ë¡œ ì œì–´ ë©”ì‹œì§€ ì „ì†¡: {text}")
    except OSError as exc:
        print(f"ì œì–´ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {exc}")

def send_pose_message(sock: socket.socket, pose: Tuple[float, float, float]) -> None:
    header = struct.pack(">L", 0)
    x, y, yaw = pose
    payload = f"POSE:{x:.3f},{y:.3f},{yaw:.3f}\n".encode("utf-8")
    try:
        sock.sendall(header + payload)
    except OSError as exc:
        print(f"POSE ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {exc}")

def command_prompt(stop_event: threading.Event, sock: socket.socket) -> None:
    print("ëª…ë ¹ ì…ë ¥ ìŠ¤ë ˆë“œ ì‹œì‘. 'robot@done' ë˜ëŠ” ê¸°íƒ€ ë¬¸ìì—´ì„ ì…ë ¥í•˜ë©´ ì„œë²„ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.")
    while not stop_event.is_set():
        try:
            user_input = input().strip()
        except EOFError:
            break
        if not user_input:
            continue
        send_control_message(sock, user_input)

def main() -> None:
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)

    sock.connect(SERVER_ADDR)
    print(f"ì„œë²„ {SERVER_ADDR[0]}:{SERVER_ADDR[1]}ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if not authenticate(sock):
        sock.close()
        sys.exit(1)

    stop_event = threading.Event()

    odom_bridge = OdometryBridge()
    if not odom_bridge.start():
        print("ì˜¤ë„ë©”íŠ¸ë¦¬ ë¸Œë¦¬ì§€ë¥¼ ì´ˆê¸°í™”í•˜ì§€ ëª»í•´ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        sock.close()
        sys.exit(1)
    motion = MotionController(odom_bridge, lambda msg: send_control_message(sock, msg))

    threading.Thread(target=receive_async, args=(sock, motion), daemon=True).start()
    threading.Thread(target=command_prompt, args=(stop_event, sock), daemon=True).start()

    cap: Optional[cv2.VideoCapture] = None

    try:
        cap, sensor_fps = configure_capture()
    except RuntimeError as exc:
        print(exc)
        motion.stop()
        odom_bridge.stop()
        sock.close()
        sys.exit(1)

    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY]

    if TARGET_FPS > 0 and sensor_fps > 0:
        stream_fps = min(float(TARGET_FPS), sensor_fps)
    elif TARGET_FPS > 0:
        stream_fps = float(TARGET_FPS)
    else:
        stream_fps = sensor_fps if sensor_fps > 0 else 0.0

    frame_interval = 1.0 / stream_fps if stream_fps > 0 else 0.0

    if TARGET_FPS > 0 and sensor_fps > TARGET_FPS + 1e-3:
        print(f"ì „ì†¡ ì£¼ê¸°ëŠ” {TARGET_FPS}fps ê¸°ì¤€ìœ¼ë¡œ ì œì–´í•©ë‹ˆë‹¤.")
    elif stream_fps > 0 and TARGET_FPS > 0 and sensor_fps > 0 and sensor_fps < TARGET_FPS - 1e-3:
        print(f"ì¹´ë©”ë¼ê°€ {sensor_fps:.1f}fpsê¹Œì§€ë§Œ ì§€ì›í•˜ì—¬ ì „ì†¡ FPSë„ ë™ì¼í•˜ê²Œ ì œí•œë©ë‹ˆë‹¤.")

    try:
        next_frame_time = time.perf_counter()
        next_pose_send = time.perf_counter()
        camera_failures = 0
        while True:
            cap.grab()
            ret, frame = cap.read()
            if not ret:
                camera_failures += 1
                if camera_failures >= CAMERA_FAILURE_LIMIT:
                    print("í”„ë ˆì„ì„ ë°˜ë³µì ìœ¼ë¡œ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                print("í”„ë ˆì„ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                time.sleep(0.2)
                continue

            camera_failures = 0

            if frame.shape[1] != FRAME_SIZE[0] or frame.shape[0] != FRAME_SIZE[1]:
                frame = cv2.resize(frame, FRAME_SIZE, interpolation=cv2.INTER_LINEAR)

            ok, encoded = cv2.imencode(".jpg", frame, encode_param)
            if not ok:
                print("JPEG ì¸ì½”ë”© ì‹¤íŒ¨. í”„ë ˆì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            payload = encoded.tobytes()
            header = struct.pack(">L", len(payload))
            try:
                sock.sendall(header + payload)
            except OSError:
                print("ì†Œì¼“ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            now = time.perf_counter()
            if now >= next_pose_send:
                if odom_bridge.has_pose():
                    pose_world = odom_bridge.get_pose(relative=False)
                    rel_x, rel_y = odom_bridge.to_relative(pose_world[0], pose_world[1])
                    pose = (rel_x, rel_y, pose_world[2])
                    send_pose_message(sock, pose)
                next_pose_send = now + POSE_SEND_INTERVAL

            if frame_interval > 0:
                next_frame_time += frame_interval
                sleep_for = next_frame_time - time.perf_counter()
                if sleep_for > 0:
                    time.sleep(sleep_for)
                else:
                    next_frame_time = time.perf_counter()
    except KeyboardInterrupt:
        print("ì‚¬ìš©ì ì¤‘ë‹¨ ìš”ì²­ìœ¼ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    finally:
        stop_event.set()
        if cap is not None:
            cap.release()
        motion.stop()
        odom_bridge.stop()
        sock.close()


if __name__ == "__main__":
    main()
